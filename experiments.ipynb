{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37332bita337cb3d562a459886fc6e869b497776",
   "display_name": "Python 3.7.3 32-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "34d317d93a37d772ab695795c108f15790d28cc6671edffe18ba0ccb60337721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    # 'O2 Grouper Pipeline - Task List.xlsx',\n",
    "    # 'P2 v3 Authorization_DS manager - list of tasks.xlsx',\n",
    "    'P2 v3 Replatforming Tasks List.xlsx',\n",
    "    # 'P2 testing tasks.xlsx',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tools.dev_o2_excel_ingestor as o2\n",
    "\n",
    "for filename in filenames:\n",
    "    print(\"Ingesting: \", filename)\n",
    "    rdf = o2.generate_rdf_from_xlsx('./tools/', filename)\n",
    "    o2.send_rdf_to_dgraph('localhost:9080', rdf)\n",
    "    print(\"Finished ingestion: \", filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfp_dfd():\n",
    "    import tools.lib.pmtx_client.query_baselines as rb\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from time import time\n",
    "\n",
    "\n",
    "    url = 'http://localhost:8080/graphql'\n",
    "\n",
    "\n",
    "    query_project_filter = {\n",
    "        \"or\": [\n",
    "            {\"name\": {\"allofterms\": \"P2 v3 Replatforming Tasks List.xlsx\"}},\n",
    "            {\"name\": {\"allofterms\": \"O2 Grouper Pipeline - Task List.xlsx\"}},\n",
    "            {\"name\": {\"allofterms\": \"P2 v3 Authorization_DS manager - list of tasks.xlsx\"}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    normalized_baseline = rb.request_and_normalize_baselines_from_pmtx(url, query_project_filter)\n",
    "    dfp, dfd = rb.baseline_to_pandas_df(normalized_baseline)\n",
    "\n",
    "\n",
    "\n",
    "    query = '''\n",
    "        query ($projects_ids:[ID!]) {\n",
    "            queryProject (filter: {and: [{id: $projects_ids} ]}) {\n",
    "                id\n",
    "                customFields\n",
    "            }\n",
    "        }\n",
    "    '''\n",
    "\n",
    "    r = requests.post(url=url, json={\"query\": query, \"variables\": {\"projects_ids\": dfp.project_id.to_list()}})\n",
    "\n",
    "    project_details = r.json()['data']['queryProject']\n",
    "\n",
    "    for project in project_details:\n",
    "        if project['customFields'] is not None:\n",
    "            details = json.loads(project['customFields'])\n",
    "            project['sprint'] = (int(details['sprint'].split(' ')[1]) if details['sprint'].split(' ')[1].isdigit() else None) if 'sprint' in details else None\n",
    "        else: \n",
    "            project['sprint'] = None\n",
    "        del project['customFields']\n",
    "\n",
    "    project_details = pd.DataFrame(project_details)\n",
    "    dfp = dfp.merge(project_details, how='left', left_on='project_id', right_on='id')\n",
    "    dfp.drop(columns=['id'], inplace=True)\n",
    "\n",
    "    print(\"acquiring completed.\")\n",
    "\n",
    "    return dfp, dfd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.lib.task_assignee_estimators.solver_base as base\n",
    "\n",
    "est = base.SolverBase(dfp,dfd)\n",
    "\n",
    "est.config()\n",
    "est.initialize()\n",
    "\n",
    "est.find_incorrect_dependencies_FS()\n",
    "\n",
    "# est.lp\n",
    "\n",
    "# dfp[dfp.start.notnull() & dfp.finish.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "import tools.lib.task_assignee_estimators.primitive_estimation as estimator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "solver = estimator.ProposeAssigment()\n",
    "\n",
    "start_date = dfp.start.min()\n",
    "\n",
    "\n",
    "projects = dfp.copy(deep=True)\n",
    "dependencies = dfd.copy(deep=True)\n",
    "\n",
    "solver.av = estimator.create_availability_calendar(number_of_users=9)\n",
    "solver.av['project_id'] = None\n",
    "\n",
    "algo_time_start = time()\n",
    "\n",
    "for sprint in [6,7,8,9,10]:\n",
    "    solver.projects = projects[(projects.sprint < sprint)]\n",
    "    # print(solver.projects[solver.projects.sprint == 6].shape[0])\n",
    "    solver.dependencies = dependencies\n",
    "    solver.av[solver.av.project_id.notnull()]\n",
    "\n",
    "    # # Calculation part\n",
    "    solver.initialize(start_date)\n",
    "    solver.av[solver.av.project_id.notnull()]\n",
    "    # x1 = solver.av.copy(deep=True)\n",
    "\n",
    "    # finish_date = solver.assign_projects_from_last_task_based_on_infinite_resources(partial_update=True, partial_update_from=pd.Timestamp('2021-01-01', tz='UTC'), one_worker_per_project=True)\n",
    "    finish_date = solver.assign_projects_by_start_based_on_infinite_resources(partial_update=True, partial_update_from=pd.Timestamp('2021-01-01', tz='UTC'), one_worker_per_project=True)\n",
    "\n",
    "    solver.av[solver.av.project_id.notnull()]\n",
    "    # x2 = solver.av.copy(deep=True)\n",
    "\n",
    "    solver.update_projects()\n",
    "    solver.av[solver.av.project_id.notnull()]\n",
    "\n",
    "\n",
    "    for index, row in solver.projects.iterrows(): # TODO: find better way to update\n",
    "        projects.loc[projects.project_id == row['project_id'], 'start'] = solver.projects[solver.projects.project_id == row['project_id']].start.iloc[0]\n",
    "        projects.loc[projects.project_id == row['project_id'], 'finish'] = solver.projects[solver.projects.project_id == row['project_id']].finish.iloc[0]\n",
    "\n",
    "\n",
    "    break\n",
    "\n",
    "# ## resolve rest (NULLs)\n",
    "# solver.projects = projects\n",
    "# # print(solver.projects[solver.projects.sprint == 6].shape[0])\n",
    "# solver.dependencies = dependencies\n",
    "\n",
    "# # # Calculation part\n",
    "# solver.initialize(start_date)\n",
    "\n",
    "# finish_date = solver.assign_projects_by_start_based_on_infinite_resources(partial_update=True, partial_update_from=pd.Timestamp('2021-01-01', tz='UTC'), one_worker_per_project=True)\n",
    "\n",
    "# solver.update_projects()\n",
    "\n",
    "# # projects[(projects.sprint < sprint), 'start'] = solver.projects\n",
    "# for index, row in solver.projects.iterrows(): # TODO: find better way to update\n",
    "#     projects.loc[projects.project_id == row['project_id'], 'start'] = solver.projects[solver.projects.project_id == row['project_id']].start.iloc[0]\n",
    "#     projects.loc[projects.project_id == row['project_id'], 'finish'] = solver.projects[solver.projects.project_id == row['project_id']].finish.iloc[0]\n",
    "\n",
    "\n",
    "algo_time_finish = time()\n",
    "\n",
    "print('Project finish timestamp: ' + str(finish_date))\n",
    "print('Calculation time [s]: ' + str(algo_time_finish - algo_time_start))\n",
    "print('Unassigned workers time during project: ' + str((solver.av[solver.av.project_id.isnull() & (solver.av.start <= finish_date)].finish - solver.av[solver.av.project_id.isnull() & (solver.av.start <= finish_date)].start).sum()))\n",
    "\n",
    "print(\"Finished.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprt = 6\n",
    "print(\"min: \", solver.projects[solver.projects.sprint == sprt].start.min())\n",
    "print(\"min: \", solver.projects[solver.projects.sprint == sprt].start.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "d:\\pmt_x\\tools\\lib\\pmtx_client\\mutate_baselines.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  children['parent_id'] = root_id\n",
      "{'data': {'addProjectBaseline': {'projectBaseline': [{'id': '0xa6dc', 'project': {'id': '0x2e8a'}, 'baseline': {'id': '0xa61d'}}]}}, 'extensions': {'touched_uids': 5724, 'tracing': {'version': 1, 'startTime': '2021-05-11T20:48:16.5740502Z', 'endTime': '2021-05-11T20:48:16.689654Z', 'duration': 115603800, 'execution': {'resolvers': [{'path': ['addProjectBaseline'], 'parentType': 'Mutation', 'fieldName': 'addProjectBaseline', 'returnType': 'AddProjectBaselinePayload', 'startOffset': 3398400, 'duration': 112166700, 'dgraph': [{'label': 'mutation', 'startOffset': 16456700, 'duration': 88326000}, {'label': 'query', 'startOffset': 109568900, 'duration': 5857900}]}]}}}}\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import tools.lib.pmtx_client.mutate_baselines as mb\n",
    "import datetime\n",
    "\n",
    "url = 'http://localhost:8080/graphql'\n",
    "\n",
    "solver.projects.drop(columns=['sprint'], inplace=True)\n",
    "\n",
    "root_id = \"0x2e8a\"\n",
    "baseline_name = \"X last finish solver - from actual times \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "baseline_id = mb.add_baseline_and_return_id(url, baseline_name, root_id)\n",
    "mb.add_project_baseline(url, solver.projects, baseline_id, root_id)\n",
    "mb.modify_project_baseline_predecessors(url, solver.dependencies, baseline_id)\n",
    "mb.add_resource_baseline(url, solver.av, baseline_id)\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "import tools.lib.task_assignee_estimators.primitive_estimation as estimator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "solver = estimator.ProposeAssigment()\n",
    "\n",
    "start_date = dfp.start.min()\n",
    "\n",
    "solver.projects = dfp.copy(deep=True)\n",
    "solver.dependencies = dfd.copy(deep=True)\n",
    "# solver.av = pd.DataFrame([], columns=['user_id', 'start', 'finish'])\n",
    "solver.av = estimator.create_availability_calendar(number_of_users=9)\n",
    "# solver.av = expander.create_availability_frame()\n",
    "solver.av['project_id'] = None\n",
    "print(solver.av.shape[0])\n",
    "\n",
    "# Calculation part\n",
    "\n",
    "solver.initialize(start_date)\n",
    "\n",
    "\n",
    "algo_time_start = time()\n",
    "\n",
    "\n",
    "finish_date = solver.assign_projects_infinite_resources()\n",
    "# finish_date = solver.assign_projects_to_resources_first_free(one_worker_per_project=True)\n",
    "# finish_date = solver.assign_projects_by_start_based_on_infinite_resources(one_worker_per_project=True)\n",
    "# finish_date = solver.assign_projects_by_start_based_on_infinite_resources(partial_update=True, partial_update_from=pd.Timestamp('2021-01-01', tz='UTC'), one_worker_per_project=True)\n",
    "\n",
    "print(solver.av.shape[0])\n",
    "solver.update_projects()\n",
    "\n",
    "algo_time_finish = time()\n",
    "\n",
    "print('Project finish timestamp: ' + str(finish_date))\n",
    "print('Calculation time [s]: ' + str(algo_time_finish - algo_time_start))\n",
    "# print('Unassigned workers time during project: ' + str((solver.av[solver.av.project_id.isnull() & (solver.av.start <= finish_date)].finish - solver.av[solver.av.project_id.isnull() & (solver.av.start <= finish_date)].start).sum()))\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acquiring completed.\n",
      "1075\n",
      "1146\n",
      "Project finish timestamp: None\n",
      "Calculation time [s]: 6.133681058883667\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "def get_dfp_dfd():\n",
    "    import tools.lib.pmtx_client.query_baselines as rb\n",
    "    import requests\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from time import time\n",
    "\n",
    "\n",
    "    url = 'http://localhost:8080/graphql'\n",
    "\n",
    "\n",
    "    query_project_filter = {\n",
    "        \"or\": [\n",
    "            {\"name\": {\"allofterms\": \"P2 v3 Replatforming Tasks List.xlsx\"}},\n",
    "            {\"name\": {\"allofterms\": \"O2 Grouper Pipeline - Task List.xlsx\"}},\n",
    "            {\"name\": {\"allofterms\": \"P2 v3 Authorization_DS manager - list of tasks.xlsx\"}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    normalized_baseline = rb.request_and_normalize_baselines_from_pmtx(url, query_project_filter)\n",
    "    dfp, dfd = rb.baseline_to_pandas_df(normalized_baseline)\n",
    "\n",
    "\n",
    "\n",
    "    query = '''\n",
    "        query ($projects_ids:[ID!]) {\n",
    "            queryProject (filter: {and: [{id: $projects_ids} ]}) {\n",
    "                id\n",
    "                customFields\n",
    "            }\n",
    "        }\n",
    "    '''\n",
    "\n",
    "    r = requests.post(url=url, json={\"query\": query, \"variables\": {\"projects_ids\": dfp.project_id.to_list()}})\n",
    "\n",
    "    project_details = r.json()['data']['queryProject']\n",
    "\n",
    "    for project in project_details:\n",
    "        if project['customFields'] is not None:\n",
    "            details = json.loads(project['customFields'])\n",
    "            project['sprint'] = (int(details['sprint'].split(' ')[1]) if details['sprint'].split(' ')[1].isdigit() else None) if 'sprint' in details else None\n",
    "        else: \n",
    "            project['sprint'] = None\n",
    "        del project['customFields']\n",
    "\n",
    "    project_details = pd.DataFrame(project_details)\n",
    "    dfp = dfp.merge(project_details, how='left', left_on='project_id', right_on='id')\n",
    "    dfp.drop(columns=['id'], inplace=True)\n",
    "\n",
    "    print(\"acquiring completed.\")\n",
    "\n",
    "    return dfp, dfd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "import tools.lib.task_assignee_estimators.last_finish_solver as estimator\n",
    "\n",
    "\n",
    "dfp, dfd = get_dfp_dfd()\n",
    "\n",
    "solver = estimator.LastFinishSolver(dfp.copy(deep=True),dfd.copy(deep=True))\n",
    "\n",
    "solver.config()\n",
    "\n",
    "\n",
    "solver.av = estimator.LastFinishSolver.create_availability_calendar(start_time=pd.Timestamp('2021-05-02 21:04:56.092887+0000'), number_of_users=5)\n",
    "\n",
    "solver.av['project_id'] = None\n",
    "print(solver.av.shape[0])\n",
    "\n",
    "# Calculation part\n",
    "\n",
    "solver.initialize()\n",
    "\n",
    "\n",
    "algo_time_start = time()\n",
    "\n",
    "\n",
    "finish_date = solver.allocate_projects(create_plan_from_scratch=False)\n",
    "# finish_date = solver.assign_projects_to_resources_first_free(one_worker_per_project=True)\n",
    "# finish_date = solver.assign_projects_by_start_based_on_infinite_resources(one_worker_per_project=True)\n",
    "# finish_date = solver.assign_projects_by_start_based_on_infinite_resources(partial_update=True, partial_update_from=pd.Timestamp('2021-01-01', tz='UTC'), one_worker_per_project=True)\n",
    "\n",
    "print(solver.av.shape[0])\n",
    "solver.update_projects()\n",
    "\n",
    "algo_time_finish = time()\n",
    "\n",
    "print('Project finish timestamp: ' + str(finish_date))\n",
    "print('Calculation time [s]: ' + str(algo_time_finish - algo_time_start))\n",
    "# print('Unassigned workers time during project: ' + str((solver.av[solver.av.project_id.isnull() & (solver.av.start <= finish_date)].finish - solver.av[solver.av.project_id.isnull() & (solver.av.start <= finish_date)].start).sum()))\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of same values 82\nNumber of different values 0\n22 days 23:30:00 vs 22 days 23:30:00\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [project_id, worktime_grouped, worktime]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project_id</th>\n      <th>worktime_grouped</th>\n      <th>worktime</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "av = solver.av.copy(deep=True)\n",
    "av['worktime_grouped'] = av.finish - av.start\n",
    "grouped = av[['project_id', 'worktime_grouped']].groupby('project_id').sum()\n",
    "merged = grouped.merge(solver.projects[['project_id', 'worktime']], on='project_id')\n",
    "print('Number of same values', merged[merged.worktime_grouped == merged.worktime].shape[0])\n",
    "print('Number of different values', merged[merged.worktime_grouped != merged.worktime].shape[0])\n",
    "print(merged.worktime_grouped.sum(), 'vs', merged.worktime.sum())\n",
    "merged[merged.worktime_grouped != merged.worktime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(solver.av.project_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                start                           finish  \\\n",
       "439  2021-05-14 08:00:00.092887+00:00 2021-05-14 15:30:00.092887+00:00   \n",
       "1119 2021-05-13 11:30:00.092887+00:00 2021-05-13 16:00:00.092887+00:00   \n",
       "\n",
       "      resource_id project_id  \n",
       "439             2     0x2edb  \n",
       "1119            2     0x2edb  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>finish</th>\n      <th>resource_id</th>\n      <th>project_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>439</th>\n      <td>2021-05-14 08:00:00.092887+00:00</td>\n      <td>2021-05-14 15:30:00.092887+00:00</td>\n      <td>2</td>\n      <td>0x2edb</td>\n    </tr>\n    <tr>\n      <th>1119</th>\n      <td>2021-05-13 11:30:00.092887+00:00</td>\n      <td>2021-05-13 16:00:00.092887+00:00</td>\n      <td>2</td>\n      <td>0x2edb</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "solver.av[solver.av.project_id == '0x2edb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    project_id parent_id                            start  \\\n",
       "138     0x2edb    0x3105 2021-05-13 11:30:00.092887+00:00   \n",
       "\n",
       "                              finish        worktime  \n",
       "138 2021-05-14 15:30:00.092887+00:00 0 days 12:00:00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>project_id</th>\n      <th>parent_id</th>\n      <th>start</th>\n      <th>finish</th>\n      <th>worktime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>138</th>\n      <td>0x2edb</td>\n      <td>0x3105</td>\n      <td>2021-05-13 11:30:00.092887+00:00</td>\n      <td>2021-05-14 15:30:00.092887+00:00</td>\n      <td>0 days 12:00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "solver.projects[solver.projects.project_id == '0x2edb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}